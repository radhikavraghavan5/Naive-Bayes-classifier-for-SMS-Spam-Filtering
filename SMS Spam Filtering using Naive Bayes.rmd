---
title: "Untitled"
author: "Radhika Vijayaraghavan"
date: "`r Sys.Date()`"
output: pdf_document
---

# SMS spam filtering analysis

#### **Answer:**

-   Adding the Laplace estimator reduced the number of false positives (ham messages erroneously classified as spam) from 20 to 17 and the number of false negatives

-   The model was able to classify over 98.48% of all the SMS messages correctly as spam or ham. after tweaking the Laplace smoothing parameter to 0.1

#### **Code and Comments:**

#### Step 1: Download the data

```{r}
#| echo: false
#| include: false
# require(devtools)
# install_version("tm", version = "0.7-1", repos = "http://cran.us.r-project.org")
```

```{r}
sms_raw <- read.csv("sms_spam.csv", stringsAsFactors = FALSE)

```

#### Step 2: Exploring and preparing the data

```{r}
#examine the structure of sms data

str(sms_raw)
```

```{r}
# convert spam/ham to factor

sms_raw$type <- factor(sms_raw$type)
```

```{r}
#examining the type variable

str(sms_raw$type)
table(sms_raw$type)
```

```{r}
#build a corpus using the text mining (tm) package

sms_corpus <- SimpleCorpus(VectorSource(sms_raw$text))
```

```{r}
# examine the sms corpus

as.character(sms_corpus[[1]])
lapply(sms_corpus[1:2], as.character)
```

```{r}
# clean up the corpus using tm_map()

sms_corpus_clean <- tm_map(sms_corpus, content_transformer(tolower))

```

```{r}
# show the difference between sms_corpus and corpus_clean

as.character(sms_corpus[[1]])
as.character(sms_corpus_clean[[1]])

sms_corpus_clean <- tm_map(sms_corpus_clean, 
                           removeNumbers) # remove numbers
sms_corpus_clean <- tm_map(sms_corpus_clean, 
                           removeWords, stopwords()) # remove stop words
sms_corpus_clean <- tm_map(sms_corpus_clean, 
                           removePunctuation) # remove punctuation
```

```{r}
# create a custom function to replace (rather than remove) punctuation

removePunctuation("hello...world")

replacePunctuation <- function(x) { 
  gsub("[[:punct:]]+", " ", x) 
}

replacePunctuation("hello...world")

```

```{r}
# illustration of word stemming

wordStem(c("learn", "learned", "learning", "learns"))

```

```{r}
sms_corpus_clean <- tm_map(sms_corpus_clean, stemDocument)
sms_corpus_clean

```

```{r}
sms_corpus_clean <- tm_map(sms_corpus_clean, 
                           stripWhitespace) # eliminate unneeded whitespace
```

```{r}
# examining the final clean corpus

lapply(sms_corpus[1:3], as.character)
lapply(sms_corpus_clean[1:3], as.character)
```

```{r}
# create a document-term sparse matrix
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)
```

```{r}
# creating training and test datasets

sms_dtm_train <- sms_dtm[1:4169, ]
sms_dtm_test  <- sms_dtm[4170:5559, ]

```

```{r}
# also save the labels

sms_train_labels <- sms_raw[1:4169, ]$type
sms_test_labels  <- sms_raw[4170:5559, ]$type

```

```{r}
# check that the proportion of spam is similar

prop.table(table(sms_train_labels))
prop.table(table(sms_test_labels))

```

```{r}
# word cloud visualization
#| warning: false
wordcloud(sms_corpus_clean, min.freq = 50, 
          random.order = FALSE, 
          colors = c("red", "blue", "green", "orange", "purple"))

```

```{r}
# subset the training data into spam and ham groups
spam <- subset(sms_raw, type == "spam")
ham  <- subset(sms_raw, type == "ham")

sms_dtm_freq_train <- removeSparseTerms(sms_dtm_train, 0.999)
```

```{r}
# save frequently-appearing terms to a character vector

sms_freq_words <- findFreqTerms(sms_dtm_train, 5)
str(sms_freq_words)
```

```{r}
# create DTMs with only the frequent terms

sms_dtm_freq_train <- sms_dtm_train[ , sms_freq_words]

sms_dtm_freq_test <- sms_dtm_test[ , sms_freq_words]
```

```{r}
# convert counts to a factor

convert_counts <- function(x) 
  {
  x <- ifelse(x > 0, "Yes", "No")
  }
```

```{r}
# apply() convert_counts() to columns of train/test data

sms_train <- apply(sms_dtm_freq_train, MARGIN = 2, convert_counts)
sms_test  <- apply(sms_dtm_freq_test, MARGIN = 2, convert_counts)
```

#### Step 3: Training a model on the data

```{r}
sms_classifier <- naiveBayes(sms_train, sms_train_labels)
```

#### Step 4: Evaluating model performance

```{r}
sms_test_pred <- predict(sms_classifier, sms_test)

head(sms_test_pred)
```

```{r}
CrossTable(sms_test_pred, sms_test_labels,
           prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
           dnn = c('predicted', 'actual'))
```

```{r}
#accuracy of sms_classifier2 improved model

mean(sms_test_pred == sms_test_labels)
```

#### Step 5: Improving model performance

```{r}
sms_classifier2 <- naiveBayes(sms_train, sms_train_labels, laplace=0.1)

```

```{r}
sms_test_pred2 <- predict(sms_classifier2, sms_test)

head(sms_test_pred2, 10)
```

```{r}
CrossTable(sms_test_pred2, sms_test_labels,
           prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
           dnn = c('predicted', 'actual'))
```

```{r}
#accuracy of sms_classifier2 improved model

mean(sms_test_pred2 == sms_test_labels)
```